{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pandas import read_excel\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import random\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import svm, tree    #https://scikit-learn.org/stable/modules/svm.html\n",
    "                                 #https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from modAL.models import ActiveLearner             #https://modal-python.readthedocs.io/en/latest/content/models/ActiveLearner.html\n",
    "from modAL.uncertainty import entropy_sampling     #https://modal-python.readthedocs.io/en/latest/content/apireference/uncertainty.html\n",
    "from modAL.disagreement import vote_entropy_sampling\n",
    "\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, ClusterCentroids\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/Thesis_ActLearn_DOP_2022/main/active_learning/')\n",
    "import functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data sets\n",
    "full_data_BatchA = pd.read_csv('/home/jovyan/Thesis_ActLearn_DOP_2022/main/active_learning/data/full_data_BatchA.csv')\n",
    "y = full_data_BatchA['Label'].to_numpy()\n",
    "X_morgan = full_data_BatchA.drop(['Label'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messy part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 80:20 ration\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_morgan, y, test_size = 0.2, random_state = 0)\n",
    "  \n",
    "# describes info about train and test set\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression object\n",
    "lr = LogisticRegression()\n",
    "# train the model on train set\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
    "\n",
    "# over-sampling minority class : 0.1 corresponds to 100 of oversampling\n",
    "sampler = SMOTEN(sampling_strategy = .1 n_jobs= -1, random_state=0)\n",
    "X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression()\n",
    "lr1.fit(X_train_res, y_train_res.ravel())\n",
    "predictions1 = lr1.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
    "\n",
    "cc = ClusterCentroids(random_state=42)\n",
    "X_train_res, y_train_res = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train_res, y_train_res.ravel())\n",
    "predictions2 = lr2.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a basic experiment to select the rates of undersampling and oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firts I want to split the positive points in a uniforme way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class count in Batch A:\n",
      " Counter({0: 5120, 1: 51})\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial class count in Batch A:\\n {Counter(y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class count in TRAIN: Counter({0: 4095, 1: 41})\n",
      "Class count in TEST: Counter({0: 1025, 1: 10})\n"
     ]
    }
   ],
   "source": [
    "# Split proportionally\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_morgan, y, test_size=0.2, stratify=y, random_state=6752)\n",
    "print(f'Class count in TRAIN: {Counter(y_train)}')\n",
    "print(f'Class count in TEST: {Counter(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of combining random oversampling and undersampling for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class count in TRAIN: Counter({0: 4095, 1: 41})\n",
      "Class count in TRAIN after over-sampling: Counter({0: 4095, 1: 409})\n",
      "Class count in TRAIN after under-sampling: Counter({0: 818, 1: 409})\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial class count in TRAIN: {Counter(y_train)}')\n",
    "# define oversampling strategy\n",
    "over_sampler = SMOTEN(sampling_strategy = 0.1, n_jobs= -1, random_state=0)\n",
    "# fit and apply the transform\n",
    "x_train_re, y_train_re = over_sampler.fit_resample(X_train, y_train)\n",
    "# summarize class distribution\n",
    "print(f'Class count in TRAIN after over-sampling: {Counter(y_train_re)}')\n",
    "# define undersampling strategy\n",
    "under_sampler = ClusterCentroids(sampling_strategy = 0.5, random_state = 42)\n",
    "# fit and apply the transform\n",
    "x_train_re, y_train_re = under_sampler.fit_resample(x_train_re, y_train_re)\n",
    "# summarize class distribution\n",
    "print(f'Class count in TRAIN after under-sampling: {Counter(y_train_re)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Training a model on the initial data set\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_predicted = clf.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(f'F1-score: {f1_score(y_test, y_predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.020689655172413793\n"
     ]
    }
   ],
   "source": [
    "#Training a model\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(x_train_re, y_train_re)\n",
    "y_predicted_re = clf.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(f'F1-score: {f1_score(y_test, y_predicted_re)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!! We manage to increase the score by 2%!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Initial class count in TRAIN: {Counter(y_train)}')\n",
    "\n",
    "for o in np.arange(0.1, 1.1, 0.1):\n",
    "    # define oversampling strategy\n",
    "    over_sampler = SMOTEN(sampling_strategy = o, n_jobs= -1, random_state=0)\n",
    "    # fit and apply the transform\n",
    "    x_train_re, y_train_re = over_sampler.fit_resample(X_train, y_train)\n",
    "    # summarize class distribution\n",
    "    print(f'Class count in TRAIN after over-sampling: {Counter(y_train_re)}')\n",
    "    \n",
    "    for u in np.arange(0.1, 1.1, 0.1):\n",
    "        # define undersampling strategy\n",
    "        under_sampler = ClusterCentroids(sampling_strategy = u, random_state = 42)\n",
    "        # fit and apply the transform\n",
    "        x_train_re, y_train_re = under_sampler.fit_resample(x_train_re, y_train_re)\n",
    "        # summarize class distribution\n",
    "        print(f'Class count in TRAIN after under-sampling: {Counter(y_train_re)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuacion: Agregar el training y guardar los scores en una matrix para despues hacer un heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a model\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(x_train_re, y_train_re)\n",
    "y_predicted_re = clf.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(f'F1-score: {f1_score(y_test, y_predicted_re)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0.1, 1.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
