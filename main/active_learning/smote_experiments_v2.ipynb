{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pandas import read_excel\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import random\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import svm, tree    #https://scikit-learn.org/stable/modules/svm.html\n",
    "                                 #https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from modAL.models import ActiveLearner             #https://modal-python.readthedocs.io/en/latest/content/models/ActiveLearner.html\n",
    "from modAL.uncertainty import entropy_sampling     #https://modal-python.readthedocs.io/en/latest/content/apireference/uncertainty.html\n",
    "from modAL.disagreement import vote_entropy_sampling\n",
    "\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, ClusterCentroids, RandomUnderSampler \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/Thesis_ActLearn_DOP_2022/main/active_learning/')\n",
    "import functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data sets\n",
    "full_data_BatchA = pd.read_csv('/home/jovyan/Thesis_ActLearn_DOP_2022/main/active_learning/data/full_data_BatchA.csv')\n",
    "y = full_data_BatchA['Label'].to_numpy()\n",
    "X_morgan = full_data_BatchA.drop(['Label'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class count in Batch A:\n",
      " Counter({0: 5092, 1: 51})\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial class count in Batch A:\\n {Counter(y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class count in TRAIN: Counter({0: 4073, 1: 41})\n",
      "Class count in TEST: Counter({0: 1019, 1: 10})\n"
     ]
    }
   ],
   "source": [
    "# Split proportionally\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_morgan, y, test_size=0.2, stratify=y, random_state=6752)\n",
    "print(f'Class count in TRAIN: {Counter(y_train)}')\n",
    "print(f'Class count in TEST: {Counter(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment again..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First only over sampling the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class count in TRAIN: Counter({0: 4073, 1: 41})\n",
      "************ Experiment 0\n",
      "Re-sampling with (o = 0.1, u = None). Final count: Counter({0: 4073, 1: 407})\n",
      "Repetition\n",
      "There are 4130 unique rows after over sampling\n",
      "---Score: 0.16666666666666669\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 3), n_estimators = 100, random_state = 84723)\n",
    "over_samp_matrix2 = []\n",
    "print(f'Initial class count in TRAIN: {Counter(y_train)}')\n",
    "\n",
    "for o in np.arange(0.1, 0.2, 0.1):\n",
    "        \n",
    "    print(f'************ Experiment {counter}')\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    over_sampler = SMOTEN(sampling_strategy = o, n_jobs= -1, random_state=0)\n",
    "    # fit and apply the transform\n",
    "    x_train_re_ov, y_train_re_ov = over_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    # summarize class distribution\n",
    "    print('Re-sampling with (o = {}, u = None). Final count: {}'.format(o, Counter(y_train_re_ov)))\n",
    "    if len(y_train_re_ov) != len(np.unique(x_train_re_ov, axis=0)):\n",
    "        print(\"Repetition\")\n",
    "        x_train_re_ov_df = pd.DataFrame(x_train_re_ov)\n",
    "        print(f'There are {len(x_train_re_ov_df.value_counts())} unique rows after over sampling')\n",
    "\n",
    "    clf.fit(x_train_re_ov, y_train_re_ov)\n",
    "    y_predicted_re_ov = clf.predict(X_test)\n",
    "    score = f1_score(y_test, y_predicted_re_ov)\n",
    "    print(f'---Score: {score}')\n",
    "\n",
    "    over_samp_matrix2.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16666666666666669, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_samp_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now under-samplinf the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class count in TRAIN: Counter({0: 4073, 1: 41})\n",
      "************ Experiment 0\n",
      "Re-sampling with (o = None, u = 1.0). Final count: Counter({0: 41, 1: 41})\n",
      "There are 82 unique rows after over sampling\n",
      "---Score: 0.03305785123966942\n",
      "************ Experiment 1\n",
      "Re-sampling with (o = None, u = 0.9). Final count: Counter({0: 45, 1: 41})\n",
      "There are 86 unique rows after over sampling\n",
      "---Score: 0.03791469194312796\n",
      "************ Experiment 2\n",
      "Re-sampling with (o = None, u = 0.8). Final count: Counter({0: 51, 1: 41})\n",
      "There are 92 unique rows after over sampling\n",
      "---Score: 0.037037037037037035\n",
      "************ Experiment 3\n",
      "Re-sampling with (o = None, u = 0.7000000000000001). Final count: Counter({0: 58, 1: 41})\n",
      "There are 99 unique rows after over sampling\n",
      "---Score: 0.044117647058823525\n",
      "************ Experiment 4\n",
      "Re-sampling with (o = None, u = 0.6000000000000001). Final count: Counter({0: 68, 1: 41})\n",
      "There are 109 unique rows after over sampling\n",
      "---Score: 0.050251256281407024\n",
      "************ Experiment 5\n",
      "Re-sampling with (o = None, u = 0.5000000000000001). Final count: Counter({0: 81, 1: 41})\n",
      "There are 122 unique rows after over sampling\n",
      "---Score: 0.06015037593984963\n",
      "************ Experiment 6\n",
      "Re-sampling with (o = None, u = 0.40000000000000013). Final count: Counter({0: 102, 1: 41})\n",
      "There are 143 unique rows after over sampling\n",
      "---Score: 0.06611570247933883\n",
      "************ Experiment 7\n",
      "Re-sampling with (o = None, u = 0.30000000000000016). Final count: Counter({0: 136, 1: 41})\n",
      "There are 177 unique rows after over sampling\n",
      "---Score: 0.052631578947368425\n",
      "************ Experiment 8\n",
      "Re-sampling with (o = None, u = 0.20000000000000018). Final count: Counter({0: 204, 1: 41})\n",
      "There are 245 unique rows after over sampling\n",
      "---Score: 0.11111111111111109\n",
      "************ Experiment 9\n",
      "Re-sampling with (o = None, u = 0.1000000000000002). Final count: Counter({0: 409, 1: 41})\n",
      "There are 450 unique rows after over sampling\n",
      "---Score: 0.0909090909090909\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "under_samp_matrix = []\n",
    "print(f'Initial class count in TRAIN: {Counter(y_train)}')\n",
    "\n",
    "for u in np.arange(1.0, 0.0, -0.1):\n",
    "    \n",
    "    print(f'************ Experiment {counter}')\n",
    "    \n",
    "    # define undersampling strategy\n",
    "    under_sampler = RandomUnderSampler(sampling_strategy = u ,random_state=42)\n",
    "    # fit and apply the transform\n",
    "    x_train_re_un, y_train_re_un = under_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    # summarize class distribution\n",
    "    print('Re-sampling with (o = None, u = {}). Final count: {}'.format(u, Counter(y_train_re_un)))\n",
    "    \n",
    "    x_train_re_un_df = pd.DataFrame(x_train_re_un)\n",
    "    print(f'There are {len(x_train_re_un_df.value_counts())} unique rows after over sampling')\n",
    "    if len(y_train_re_un) != len(np.unique(x_train_re_un, axis=0)):\n",
    "        print(\"Repetition\")\n",
    "    \n",
    "    #Training and evaluating\n",
    "    clf.fit(x_train_re_un, y_train_re_un)\n",
    "    y_predicted_re_un = clf.predict(X_test)\n",
    "    score = f1_score(y_test, y_predicted_re_un)\n",
    "    print(f'---Score: {score}')\n",
    "\n",
    "    under_samp_matrix.append(score)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over-sampling creates repeated compounds with label 1 which will create problems when adding Conformal Prediction. For this reason, I will implement only under-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of combining random oversampling and undersampling for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(f'Initial class count in TRAIN: {Counter(y_train)}')\\n# define oversampling strategy 1\\x08, 409/\\nover_sampler = SMOTEN(sampling_strategy = 0.1, n_jobs= -1, random_state=0)\\n# fit and apply the transform\\nx_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)\\n# summarize class distribution\\nprint(f'Class count in TRAIN after over-sampling: {Counter(y_train_over)}') \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(f'Initial class count in TRAIN: {Counter(y_train)}')\n",
    "# define oversampling strategy 1\\10, 409/\n",
    "over_sampler = SMOTEN(sampling_strategy = 0.1, n_jobs= -1, random_state=0)\n",
    "# fit and apply the transform\n",
    "x_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)\n",
    "# summarize class distribution\n",
    "print(f'Class count in TRAIN after over-sampling: {Counter(y_train_over)}') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# define undersampling strategy\\nunder_sampler = RandomUnderSampler(sampling_strategy = 0.9 ,random_state=42)\\n# fit and apply the transform\\nx_train_under, y_train_under = under_sampler.fit_resample(x_train_over, y_train_over)\\n# summarize class distribution\\nprint(f'Class count in TRAIN after under-sampling: {Counter(y_train_under)}')\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# define undersampling strategy\n",
    "under_sampler = RandomUnderSampler(sampling_strategy = 0.9 ,random_state=42)\n",
    "# fit and apply the transform\n",
    "x_train_under, y_train_under = under_sampler.fit_resample(x_train_over, y_train_over)\n",
    "# summarize class distribution\n",
    "print(f'Class count in TRAIN after under-sampling: {Counter(y_train_under)}')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
