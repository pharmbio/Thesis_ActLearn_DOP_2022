{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pandas import read_excel\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import random\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree    #https://scikit-learn.org/stable/modules/svm.html\n",
    "                                 #https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "from modAL.models import ActiveLearner             #https://modal-python.readthedocs.io/en/latest/content/models/ActiveLearner.html\n",
    "from modAL.uncertainty import entropy_sampling     #https://modal-python.readthedocs.io/en/latest/content/apireference/uncertainty.html\n",
    "from modAL.disagreement import vote_entropy_sampling\n",
    "from modAL.multilabel import SVM_binary_minimum\n",
    "from modAL.density import information_density\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/Thesis_ActLearn_DOP_2022/main/active_learning/')\n",
    "import functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data sets\n",
    "full_data_BatchA = pd.read_csv('/home/jovyan/Thesis_ActLearn_DOP_2022/main/active_learning/data/full_data_BatchA.csv')\n",
    "y = full_data_BatchA['Label'].to_numpy()\n",
    "X_morgan = full_data_BatchA.drop(['Label'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only default values exept random state for replications\n",
    "# NOTE: SVM can be use only if the model is a SVM classifier\n",
    "lr_clf1 = LogisticRegression(random_state=0)\n",
    "svm_clf1 = SVC(random_state = 0, probability=True)\n",
    "knn_clf1 = KNeighborsClassifier(n_jobs=-1)\n",
    "rf_clf1 = RandomForestClassifier(max_depth=10, random_state=0, n_jobs = -1)\n",
    "ada_clf1 = AdaBoostClassifier(n_estimators=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for ML model\n",
    "train_size = 0.1\n",
    "test_size = 0.3\n",
    "\n",
    "# split dataset into train(- %), test(- %), unlabel(- %)\n",
    "x_train, y_train, x_test, y_test, x_pool, y_pool = fun.split(x_dataset = X_morgan, y_dataset = y, \n",
    "                                                             ini_train_size = train_size, test_size = test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inicial training set has size 361\n",
      "The inicial pool set has size 3258\n",
      "The inicial test set has size 1552\n"
     ]
    }
   ],
   "source": [
    "print(f'The inicial training set has size {len(x_train)}')\n",
    "print(f'The inicial pool set has size {len(x_pool)}')\n",
    "print(f'The inicial test set has size {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Training with RandomForestClassifier(max_depth=10, n_jobs=-1, random_state=0)\n",
      "Accuracy after query 1: 0.9903\n",
      "Accuracy after query 101: 0.9903\n",
      "Accuracy after query 201: 0.9903\n",
      "Accuracy after query 301: 0.9903\n",
      "Accuracy after query 401: 0.9903\n",
      "Accuracy after query 501: 0.9903\n",
      "Accuracy after query 601: 0.9903\n",
      "Accuracy after query 701: 0.9903\n",
      "Accuracy after query 801: 0.9903\n",
      "Accuracy after query 901: 0.9903\n",
      "Accuracy after query 1001: 0.9903\n",
      "Accuracy after query 1101: 0.9903\n",
      "Accuracy after query 1201: 0.9903\n",
      "Accuracy after query 1301: 0.9903\n",
      "Accuracy after query 1401: 0.9903\n",
      "Accuracy after query 1501: 0.9903\n",
      "Accuracy after query 1601: 0.9903\n",
      "Accuracy after query 1701: 0.9903\n",
      "Accuracy after query 1801: 0.9903\n",
      "Accuracy after query 1901: 0.9903\n",
      "Accuracy after query 2001: 0.9903\n",
      "Accuracy after query 2101: 0.9903\n",
      "********** Training with AdaBoostClassifier(n_estimators=10, random_state=0)\n",
      "Accuracy after query 1: 0.9807\n",
      "Accuracy after query 101: 0.9871\n",
      "Accuracy after query 201: 0.9826\n",
      "Accuracy after query 301: 0.9826\n",
      "Accuracy after query 401: 0.9890\n",
      "Accuracy after query 501: 0.9871\n",
      "Accuracy after query 601: 0.9903\n",
      "Accuracy after query 701: 0.9903\n",
      "Accuracy after query 801: 0.9903\n",
      "Accuracy after query 901: 0.9897\n",
      "Accuracy after query 1001: 0.9884\n",
      "Accuracy after query 1101: 0.9897\n",
      "Accuracy after query 1201: 0.9884\n",
      "Accuracy after query 1301: 0.9903\n",
      "Accuracy after query 1401: 0.9903\n",
      "Accuracy after query 1501: 0.9897\n",
      "Accuracy after query 1601: 0.9871\n",
      "Accuracy after query 1701: 0.9890\n",
      "Accuracy after query 1801: 0.9871\n",
      "Accuracy after query 1901: 0.9871\n",
      "Accuracy after query 2101: 0.9897\n",
      "\n",
      "\n",
      "Elapsed time: 5178.9864692650735 seconds\n"
     ]
    }
   ],
   "source": [
    "# Parameters for AL\n",
    "N_QUERIES = int(2*len(x_pool)/3)\n",
    "\n",
    "#Timer\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "cf_mat_x_clssifr = []\n",
    "prfmc_x_classifr = []\n",
    "Classifiers = [rf_clf1, ada_clf1]\n",
    "save = True\n",
    "for classifier in Classifiers:\n",
    "    \n",
    "    print(f'********** Training with {str(classifier)}')\n",
    "    \n",
    "    prfmc_his, cf_mat_his, learner= fun.active_learnig_train(n_queries = N_QUERIES, x_train = x_train, y_train = y_train, \n",
    "                                               x_test = x_test, y_test = y_test, x_pool = x_pool, \n",
    "                                               y_pool = y_pool, Classifier = classifier, query_str = 'density_sampling')\n",
    "    prfmc_x_classifr.append(prfmc_his)\n",
    "    cf_mat_x_clssifr.append(cf_mat_his)\n",
    "    \n",
    "    #Saving model\n",
    "    if save:\n",
    "        filename = \"\".join([\"/home/jovyan/Thesis_ActLearn_DOP_2022/main/active_learning/density_experiments/dens_euclidean_default_models/den\", str(classifier),'.sav'])\n",
    "        pickle.dump(learner, open(filename, 'wb'))\n",
    "    \n",
    "toc=timeit.default_timer()\n",
    "print(f'\\n\\nElapsed time: {toc-tic} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "fig, axes = plt.subplots(1, len(Classifiers), figsize=(18,3))\n",
    "i = 0\n",
    "for row in axes:\n",
    "    fun.plot_cf_mat(matrix = cf_mat_x_clssifr[i][-1], sub_title = str(Classifiers[i]) ,save = False, figure_name = None, ax=row)\n",
    "    i+=1\n",
    "fig.suptitle('Confusion Matrixes using Uncertainty sampling with entropy\\n', fontsize=16, y =1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
