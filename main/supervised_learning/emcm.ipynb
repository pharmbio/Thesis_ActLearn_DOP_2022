{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import random\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, f1_score, mean_squared_log_error, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn import svm, tree    #https://scikit-learn.org/stable/modules/svm.html\n",
    "                                 #https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "#-------------ACTIVE LEARNING LIBRARY\n",
    "from modAL.models import ActiveLearner             #https://modal-python.readthedocs.io/en/latest/content/models/ActiveLearner.html\n",
    "from modAL.uncertainty import entropy_sampling     #https://modal-python.readthedocs.io/en/latest/content/apireference/uncertainty.html\n",
    "from modAL.disagreement import vote_entropy_sampling\n",
    "\n",
    "#------------IMBALANCED DATA SETS LIBRARY\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, ClusterCentroids, RandomUnderSampler \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/Thesis_ActLearn_DOP_2022/main/active_learning/')\n",
    "import functions as fun\n",
    "import reg_icp as ricp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5167 rows in the Batch A\n"
     ]
    }
   ],
   "source": [
    "# Loading data sets\n",
    "cell_profiler = pd.read_csv('/home/jovyan/Thesis_ActLearn_DOP_2022/main/supervised_learning/regression_data_batchA.csv')\n",
    "print(f'There are {len(cell_profiler)} rows in the Batch A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features according to the paper\n",
    "group1 = [col for col in cell_profiler.columns if ('Granu' in col  and 'SYTO' in col) or ('Inten' in col and 'SYTO' in col) and not 'Location' in col and not 'Radial' in col]\n",
    "group2 = [col for col in cell_profiler.columns if ('Granu' in col  and 'CONC' in col) or ('Inten' in col and 'CONC' in col) and not 'Location' in col and not 'Radial' in col]\n",
    "group3 = [col for col in cell_profiler.columns if 'Correla' in col or 'Neig' in col]\n",
    "\n",
    "filtered_features = group1+group2+group3\n",
    "\n",
    "# Filtering\n",
    "filtered_cell_profiler = cell_profiler[filtered_features+['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output values\n",
    "X_filtered = filtered_cell_profiler.drop(['Target'], axis = 1).to_numpy()\n",
    "y = 1000*filtered_cell_profiler.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for ML model\n",
    "train_size = 0.1\n",
    "test_size = 0.3\n",
    "\n",
    "# split dataset into train(- %), test(- %), unlabel(- %)\n",
    "x_train, y_train, x_test, y_test, x_pool, y_pool = fun.split(x_dataset = X_filtered, y_dataset = y, \n",
    "                                                             ini_train_size = train_size, test_size = test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inicial training set has size 361\n",
      "The inicial pool set has size 3255\n",
      "The inicial test set has size 1551\n"
     ]
    }
   ],
   "source": [
    "print(f'The inicial training set has size {len(x_train)}')\n",
    "print(f'The inicial pool set has size {len(x_pool)}')\n",
    "print(f'The inicial test set has size {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"EXPECTED MODEL CHANGE MAXIMISATION FOR ACTIVE LEARNING IN LR\n",
    "Input:\n",
    "X_labeled = small labeled data set (called D in the paper) with n points\n",
    "y_labeled\n",
    "X_pool = the unlabelled pool set\n",
    "linear_model = the linear regression model (called f(x;theta)) in the paper\n",
    "K_members = number of regressors in the ensemble\n",
    "\n",
    "Ouput:\n",
    "x_star = the instance to be sampled for active learning\n",
    "\"\"\"\n",
    "\n",
    "def emcm_query(X_labeled, y_labeled, X_pool, linear_model, K_members):\n",
    "    \n",
    "    # 0. Train the linear regresor in X_labeled to build f(x;theta)\n",
    "    fx = linear_model.fit(X_labeled, y_labeled)\n",
    "    \n",
    "    # 1. Construct an ensemble with boostrap examples\n",
    "    Bk = AdaBoostRegressor(base_estimator = linear_model, n_estimators = K_members, random_state=5563).fit(X_labeled, y_labeled)\n",
    "    \n",
    "    # 2. for each x_candidate in x_pool do\n",
    "    modelChange_per_candidate = np.zeros(X_pool.shape[0])\n",
    "    for x_candidate_idx, x_candidate_value in enumerate(X_pool):\n",
    "        gradient_per_candidate = []\n",
    "        # 3. for each member in the ensemble\n",
    "        for k in range(K_members):\n",
    "            \n",
    "            # 4. y_k(x_candidate_value) = f_k(x_candidate_value)\n",
    "            yk_candidate = Bk.estimators_[k].predict([x_candidate_value]) \n",
    "            \n",
    "            # 5.Calculate the derivative using Eq.13:\n",
    "            delta_lk = (fx.predict([x_candidate_value]) - yk_candidate) * x_candidate_value\n",
    "            gradient_per_candidate.append(delta_lk)\n",
    "        \n",
    "        # 7. Estimate the true model change by expectation calculation over K possible labels with Eq.14\n",
    "        modelChange_per_candidate[x_candidate_idx] = (1/K_members)*np.sum(np.linalg.norm(gradient_per_candidate))\n",
    "        \n",
    "    # 8.Select the x that maximases the change\n",
    "    x_star_idx = np.argmax(modelChange_per_candidate)\n",
    "    x_star_value = X_pool[x_star_idx]\n",
    "    \n",
    "    return x_star_idx, x_star_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
