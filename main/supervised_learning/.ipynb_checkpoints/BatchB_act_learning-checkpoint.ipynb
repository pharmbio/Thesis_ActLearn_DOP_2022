{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import random\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, f1_score, mean_squared_log_error, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn import svm, tree    #https://scikit-learn.org/stable/modules/svm.html\n",
    "                                 #https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "#-------------ACTIVE LEARNING LIBRARY\n",
    "from modAL.models import ActiveLearner             #https://modal-python.readthedocs.io/en/latest/content/models/ActiveLearner.html\n",
    "from modAL.uncertainty import entropy_sampling     #https://modal-python.readthedocs.io/en/latest/content/apireference/uncertainty.html\n",
    "from modAL.disagreement import vote_entropy_sampling\n",
    "\n",
    "#------------IMBALANCED DATA SETS LIBRARY\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, ClusterCentroids, RandomUnderSampler \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/Thesis_ActLearn_DOP_2022/main/active_learning/')#<<<<----CHANGE HERE DEPEINDING ON YOUR PATH\n",
    "import functions as fun\n",
    "import reg_icp as ricp\n",
    "import emcm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are (5160, 285) rows and cols in the Batch B\n"
     ]
    }
   ],
   "source": [
    "# Loading data sets\n",
    "filtered_cell_profiler_B = pd.read_csv('/home/jovyan/Thesis_ActLearn_DOP_2022/main/supervised_learning/filtered_cell_profiler_B.csv')\n",
    "print(f'There are {filtered_cell_profiler_B.shape} rows and cols in the Batch B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating training and tests sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the input values\n",
    "X_filtered =  filtered_cell_profiler_B.iloc[:,:-1].to_numpy()\n",
    "\n",
    "# Re-scale\n",
    "scaler = StandardScaler()\n",
    "X_filtered = pd.DataFrame(scaler.fit_transform(X_filtered))\n",
    "X_filtered = X_filtered.to_numpy()\n",
    "\n",
    "# Output values\n",
    "y = 1000*filtered_cell_profiler_B.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for ML model\n",
    "train_size = 0.1\n",
    "test_size = 0.3\n",
    "\n",
    "# split dataset into train(- %), test(- %), unlabel(- %)\n",
    "x_train, y_train, x_test, y_test, x_pool, y_pool = fun.split(x_dataset = X_filtered, y_dataset = y, \n",
    "                                                             ini_train_size = train_size, test_size = test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inicial training set has size 361\n",
      "The inicial pool set has size 3251\n",
      "The inicial test set has size 1548\n"
     ]
    }
   ],
   "source": [
    "print(f'The inicial training set has size {len(x_train)}')\n",
    "print(f'The inicial pool set has size {len(x_pool)}')\n",
    "print(f'The inicial test set has size {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside AL\n",
      "Accuracy after query 100: 0.7471\n",
      "Accuracy after query 200: 0.7132\n",
      "Accuracy after query 300: 0.6554\n",
      "Accuracy after query 400: 0.6331\n",
      "Accuracy after query 500: 0.5932\n",
      "Accuracy after query 600: 0.5751\n",
      "Accuracy after query 700: 0.5989\n",
      "Accuracy after query 800: 0.5745\n",
      "Accuracy after query 900: 0.5687\n",
      "Accuracy after query 1000: 0.5570\n",
      "Accuracy after query 1100: 0.5464\n",
      "Accuracy after query 1200: 0.5444\n",
      "Accuracy after query 1300: 0.5331\n",
      "Accuracy after query 1400: 0.5277\n",
      "Accuracy after query 1500: 0.5229\n",
      "Accuracy after query 1600: 0.5222\n",
      "Accuracy after query 1700: 0.5170\n",
      "Accuracy after query 1800: 0.5182\n",
      "Accuracy after query 1900: 0.5167\n",
      "Accuracy after query 2000: 0.5179\n",
      "Accuracy after query 2100: 0.5131\n",
      "Accuracy after query 2200: 0.5112\n",
      "Accuracy after query 2300: 0.5137\n",
      "Accuracy after query 2400: 0.5116\n",
      "Accuracy after query 2500: 0.5073\n",
      "Target reached! \n",
      " Number of queries performed 2595\n"
     ]
    }
   ],
   "source": [
    "#Target from supervised machine learning\n",
    "target = 0.4964\n",
    "linear_model_v2 = Ridge(alpha=0.1, random_state=0)\n",
    "\n",
    "# Parameters for AL\n",
    "k_members = 3\n",
    "\n",
    "#Define query strategy \n",
    "query_str = emcm.emcm_query\n",
    "    \n",
    "performance_history_v2 = []\n",
    "\n",
    "#Fit model to initial data\n",
    "linear_model_v2.fit(x_train, y_train)\n",
    "\n",
    "#Making predictions\n",
    "y_pred = linear_model_v2.predict(x_test)\n",
    "\n",
    "#Calculate and report our model's accuracy.\n",
    "model_accuracy = mean_squared_error(y_pred , y_test)\n",
    "\n",
    "# Save our model's performance for plotting.\n",
    "performance_history_v2.append(model_accuracy)\n",
    "collections = 0\n",
    "\n",
    "# Allow our model to query our unlabeled dataset for the most\n",
    "# informative points according to our query strategy emcm.\n",
    "while len(x_pool) > 0:\n",
    "    \n",
    "    if collections == 0:\n",
    "        print('Inside AL')\n",
    "    \n",
    "    #Query for a new point\n",
    "    query_index, query_instance = query_str(x_train, y_train, x_pool, linear_model_v2, k_members)\n",
    "    collections += 1\n",
    "    \n",
    "    # Teach our ActiveLearner model the record it has requested.\n",
    "    XX, yy = x_pool[query_index].reshape(1, -1), y_pool[query_index].reshape(1, )\n",
    "    x_train = np.append(x_train, XX, axis = 0)\n",
    "    y_train = np.append(y_train, yy, axis = 0)\n",
    "\n",
    "    # Remove the queried instance from the unlabeled pool.\n",
    "    x_pool, y_pool = np.delete(x_pool, query_index, axis=0), np.delete(y_pool, query_index)\n",
    "    \n",
    "    # Re- training in new data\n",
    "    linear_model_v2.fit(x_train, y_train)\n",
    "    \n",
    "    #Predict given the new point\n",
    "    y_pred = linear_model_v2.predict(x_test)\n",
    "    \n",
    "    #Store performance\n",
    "    model_accuracy = mean_squared_error(y_pred , y_test)\n",
    "    performance_history_v2.append(model_accuracy)\n",
    "\n",
    "    if collections % 100 == 0:\n",
    "        print('Accuracy after query {n}: {acc:0.4f}'.format(n = collections, acc = model_accuracy))\n",
    "    \n",
    "    if abs(target - model_accuracy) < 0.005:\n",
    "        print(f'Target reached! \\n Number of queries performed {collections}')\n",
    "        #Saving model\n",
    "        filename = \"\".join([str(linear_model_v2),'.sav'])\n",
    "        pickle.dump(linear_model_v2, open(filename, 'wb'))\n",
    "        break\n",
    "    \n",
    "    if len(x_pool) == 0:\n",
    "        #Saving model\n",
    "        filename = \"\".join([str(linear_model_v2),'.sav'])\n",
    "        pickle.dump(linear_model_v2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for plots\n",
    "d_v2_BatchB = {'performance_history_v2':performance_history_v2,'collections':collections}\n",
    "with open('d_v2_BatchB.pkl', 'wb') as f:\n",
    "    pickle.dump(d_v2_BatchB, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"xxx = np.arange(361, 3257+360, 1)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9,5))\n",
    "ax.plot(xxx, performance_history_v2, color=[.937, .275, .282], linewidth=1.5)\n",
    "ax.set_ylim([0.3, 0.5])\n",
    "ax.set_xlim([361, 3255])\n",
    "plt.axhline(y = 0.3215, color=[.98, .702, .447], linestyle='-', linewidth=2)\n",
    "\n",
    "ax.set_ylabel('Mean squared error (MSE)', color=\"black\", fontsize=14)   \n",
    "ax.set_xlabel('$X_{train}$  size', color=\"black\", fontsize=14)\n",
    "ax.set_title('Batch A', color=\"black\", fontsize=18)\n",
    "ax.legend(['MSE after querying', 'Mean MSE with the whole trainig set'])\n",
    "\n",
    "#plt.savefig('AL_1_Ridge_regre_batchA.jpg',bbox_inches='tight', dpi=150)\n",
    "\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for ML model\n",
    "train_size = 0.2\n",
    "test_size = 0.2\n",
    "\n",
    "# split dataset into train(- %), test(- %), unlabel(- %)\n",
    "x_train, y_train, x_test, y_test, x_pool, y_pool = fun.split(x_dataset = X_filtered, y_dataset = y, \n",
    "                                                             ini_train_size = train_size, test_size = test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inicial training set has size 825\n",
      "The inicial pool set has size 3303\n",
      "The inicial test set has size 1032\n"
     ]
    }
   ],
   "source": [
    "print(f'The inicial training set has size {len(x_train)}')\n",
    "print(f'The inicial pool set has size {len(x_pool)}')\n",
    "print(f'The inicial test set has size {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside AL\n",
      "Accuracy after query 100: 0.6924\n",
      "Accuracy after query 200: 0.5984\n",
      "Accuracy after query 300: 0.5803\n",
      "Accuracy after query 400: 0.6056\n",
      "Accuracy after query 500: 0.5848\n",
      "Accuracy after query 600: 0.5973\n",
      "Accuracy after query 700: 0.5845\n",
      "Accuracy after query 800: 0.5821\n",
      "Accuracy after query 900: 0.5848\n",
      "Accuracy after query 1000: 0.5847\n",
      "Accuracy after query 1100: 0.5739\n",
      "Accuracy after query 1200: 0.5640\n",
      "Accuracy after query 1300: 0.5647\n",
      "Accuracy after query 1400: 0.5589\n",
      "Accuracy after query 1500: 0.5543\n",
      "Accuracy after query 1600: 0.5569\n",
      "Accuracy after query 1700: 0.5545\n",
      "Accuracy after query 1800: 0.5541\n",
      "Accuracy after query 1900: 0.5570\n",
      "Accuracy after query 2000: 0.5526\n",
      "Accuracy after query 2100: 0.5483\n",
      "Accuracy after query 2200: 0.5480\n",
      "Accuracy after query 2300: 0.5432\n",
      "Accuracy after query 2400: 0.5491\n",
      "Accuracy after query 2500: 0.5502\n",
      "Accuracy after query 2600: 0.5512\n",
      "Accuracy after query 2700: 0.5524\n",
      "Accuracy after query 2800: 0.5454\n",
      "Accuracy after query 2900: 0.5436\n",
      "Accuracy after query 3000: 0.5417\n",
      "Accuracy after query 3100: 0.5410\n",
      "Accuracy after query 3200: 0.5403\n",
      "Accuracy after query 3300: 0.5418\n"
     ]
    }
   ],
   "source": [
    "#Target from supervised machine learning\n",
    "target = 0.4964\n",
    "linear_model_v3 = Ridge(alpha=0.1, random_state=0)\n",
    "\n",
    "# Parameters for AL\n",
    "k_members = 3\n",
    "\n",
    "#Define query strategy \n",
    "query_str = emcm.emcm_query\n",
    "    \n",
    "performance_history_v3 = []\n",
    "\n",
    "#Fit model to initial data\n",
    "linear_model_v3.fit(x_train, y_train)\n",
    "\n",
    "#Making predictions\n",
    "y_pred = linear_model_v3.predict(x_test)\n",
    "\n",
    "#Calculate and report our model's accuracy.\n",
    "model_accuracy = mean_squared_error(y_pred , y_test)\n",
    "\n",
    "# Save our model's performance for plotting.\n",
    "performance_history_v3.append(model_accuracy)\n",
    "collections = 0\n",
    "\n",
    "# Allow our model to query our unlabeled dataset for the most\n",
    "# informative points according to our query strategy emcm.\n",
    "while len(x_pool) > 0:\n",
    "    \n",
    "    if collections == 0:\n",
    "        print('Inside AL')\n",
    "    \n",
    "    #Query for a new point\n",
    "    query_index, query_instance = query_str(x_train, y_train, x_pool, linear_model_v3, k_members)\n",
    "    collections += 1\n",
    "    \n",
    "    # Teach our ActiveLearner model the record it has requested.\n",
    "    XX, yy = x_pool[query_index].reshape(1, -1), y_pool[query_index].reshape(1, )\n",
    "    x_train = np.append(x_train, XX, axis = 0)\n",
    "    y_train = np.append(y_train, yy, axis = 0)\n",
    "\n",
    "    # Remove the queried instance from the unlabeled pool.\n",
    "    x_pool, y_pool = np.delete(x_pool, query_index, axis=0), np.delete(y_pool, query_index)\n",
    "    \n",
    "    # Re- training in new data\n",
    "    linear_model_v3.fit(x_train, y_train)\n",
    "    \n",
    "    #Predict given the new point\n",
    "    y_pred = linear_model_v3.predict(x_test)\n",
    "    \n",
    "    #Store performance\n",
    "    model_accuracy = mean_squared_error(y_pred , y_test)\n",
    "    performance_history_v3.append(model_accuracy)\n",
    "\n",
    "    if collections % 100 == 0:\n",
    "        print('Accuracy after query {n}: {acc:0.4f}'.format(n = collections, acc = model_accuracy))\n",
    "    \n",
    "    if abs(target - model_accuracy) < 0.005:\n",
    "        print(f'Target reached! \\n Number of queries performed {collections}')\n",
    "        #Saving model\n",
    "        filename = \"\".join([str(linear_model_v3),'.sav'])\n",
    "        pickle.dump(linear_model_v3, open(filename, 'wb'))\n",
    "        break\n",
    "        \n",
    "    if len(x_pool) == 0:\n",
    "        #Saving model\n",
    "        filename = \"\".join([str(linear_model_v3),'.sav'])\n",
    "        pickle.dump(linear_model_v3, open(filename, 'wb'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_v3_BatchB = {'performance_history_v3':performance_history_v3,'collections':collections}\n",
    "with open('d_v3_BatchB.pkl', 'wb') as f:\n",
    "    pickle.dump(d_v3_BatchB, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"xxx = np.arange(826, len(x_train) + 1, 1)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9,5))\n",
    "ax.plot(xxx, performance_history_v3, color=[.937, .275, .282], linewidth=1.5)\n",
    "ax.set_ylim([0.3, 0.5])\n",
    "ax.set_xlim([826, len(x_train) + 1])\n",
    "plt.axhline(y = 0.3215, color=[.98, .702, .447], linestyle='-', linewidth=2)\n",
    "\n",
    "ax.set_ylabel('Mean squared error (MSE)', color=\"black\", fontsize=14)   \n",
    "ax.set_xlabel('$X_{train}$  size', color=\"black\", fontsize=14)\n",
    "ax.set_title('Batch A', color=\"black\", fontsize=18)\n",
    "ax.legend(['MSE after querying', 'Mean MSE with the whole trainig set'])\n",
    "\n",
    "#plt.savefig('AL_2_Ridge_regre_batchA.jpg',bbox_inches='tight', dpi=150)\n",
    "\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
