{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import random\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report, f1_score, mean_squared_log_error, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn import svm, tree    #https://scikit-learn.org/stable/modules/svm.html\n",
    "                                 #https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "#-------------ACTIVE LEARNING LIBRARY\n",
    "from modAL.models import ActiveLearner             #https://modal-python.readthedocs.io/en/latest/content/models/ActiveLearner.html\n",
    "from modAL.uncertainty import entropy_sampling     #https://modal-python.readthedocs.io/en/latest/content/apireference/uncertainty.html\n",
    "from modAL.disagreement import vote_entropy_sampling\n",
    "\n",
    "#------------IMBALANCED DATA SETS LIBRARY\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, ClusterCentroids, RandomUnderSampler \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/Thesis_ActLearn_DOP_2022/main/active_learning/')\n",
    "import functions as fun\n",
    "import reg_icp as ricp\n",
    "import emcm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5167 rows in the Batch A\n"
     ]
    }
   ],
   "source": [
    "# Loading data sets\n",
    "cell_profiler = pd.read_csv('/home/jovyan/Thesis_ActLearn_DOP_2022/main/supervised_learning/regression_data_batchA.csv')\n",
    "print(f'There are {len(cell_profiler)} rows in the Batch A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features according to the paper\n",
    "group1 = [col for col in cell_profiler.columns if ('Granu' in col  and 'SYTO' in col) or ('Inten' in col and 'SYTO' in col) and not 'Location' in col and not 'Radial' in col]\n",
    "group2 = [col for col in cell_profiler.columns if ('Granu' in col  and 'CONC' in col) or ('Inten' in col and 'CONC' in col) and not 'Location' in col and not 'Radial' in col]\n",
    "group3 = [col for col in cell_profiler.columns if 'Correla' in col or 'Neig' in col]\n",
    "\n",
    "filtered_features = group1+group2+group3\n",
    "\n",
    "# Filtering\n",
    "filtered_cell_profiler = cell_profiler[filtered_features+['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output values\n",
    "X_filtered = filtered_cell_profiler.drop(['Target'], axis = 1).to_numpy()\n",
    "y = 1000*filtered_cell_profiler.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for ML model\n",
    "train_size = 0.1\n",
    "test_size = 0.3\n",
    "\n",
    "# split dataset into train(- %), test(- %), unlabel(- %)\n",
    "x_train, y_train, x_test, y_test, x_pool, y_pool = fun.split(x_dataset = X_filtered, y_dataset = y, \n",
    "                                                             ini_train_size = train_size, test_size = test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inicial training set has size 361\n",
      "The inicial pool set has size 3255\n",
      "The inicial test set has size 1551\n"
     ]
    }
   ],
   "source": [
    "print(f'The inicial training set has size {len(x_train)}')\n",
    "print(f'The inicial pool set has size {len(x_pool)}')\n",
    "print(f'The inicial test set has size {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the best models for analysis\n",
    "linear_model = Ridge(alpha=1.3, random_state=0)\n",
    "best_tree = DecisionTreeRegressor(max_depth = 5, random_state=0)\n",
    "best_ada = AdaBoostRegressor(base_estimator = best_tree, n_estimators = 100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after query 1: 0.4219\n",
      "Accuracy after query 101: 0.4295\n",
      "Accuracy after query 201: 0.4049\n",
      "Accuracy after query 301: 0.3967\n",
      "Accuracy after query 401: 0.3889\n",
      "Accuracy after query 501: 0.3817\n",
      "Accuracy after query 601: 0.3806\n",
      "Accuracy after query 701: 0.3741\n",
      "Accuracy after query 801: 0.3671\n",
      "Accuracy after query 901: 0.3666\n",
      "Accuracy after query 1001: 0.3649\n",
      "Accuracy after query 1101: 0.3639\n",
      "Accuracy after query 1201: 0.3643\n",
      "Accuracy after query 1301: 0.3642\n",
      "Accuracy after query 1401: 0.3635\n",
      "Accuracy after query 1501: 0.3631\n",
      "Accuracy after query 1601: 0.3625\n",
      "Accuracy after query 1701: 0.3615\n",
      "Accuracy after query 1801: 0.3615\n",
      "Accuracy after query 1901: 0.3614\n",
      "Accuracy after query 2001: 0.3604\n",
      "Accuracy after query 2101: 0.3591\n"
     ]
    }
   ],
   "source": [
    "# Parameters for AL\n",
    "N_QUERIES = int(2*len(x_pool)/3)\n",
    "k_members = 3\n",
    "\n",
    "#Define query strategy \n",
    "query_str = emcm.emcm_query\n",
    "#learner = ActiveLearner(estimator= best_ridge, query_strategy = query_str, X_training = x_train, y_training = y_train)\n",
    "    \n",
    "performance_history = []\n",
    "cf_matrix_history = []\n",
    "\n",
    "#Fit model to initial data\n",
    "linear_model.fit(x_train, y_train)\n",
    "\n",
    "#Making predictions\n",
    "y_pred = linear_model.predict(x_test)\n",
    "\n",
    "#Calculate and report our model's accuracy.\n",
    "model_accuracy = mean_squared_error(y_pred , y_test)\n",
    "\n",
    "# Save our model's performance for plotting.\n",
    "performance_history.append(model_accuracy)\n",
    "\n",
    "# Allow our model to query our unlabeled dataset for the most\n",
    "# informative points according to our query strategy emcm.\n",
    "for index in range(N_QUERIES):\n",
    "\n",
    "    #Query for a new point\n",
    "    query_index, query_instance = query_str(x_train, y_train, x_pool, linear_model, k_members)\n",
    "    \n",
    "    # Teach our ActiveLearner model the record it has requested.\n",
    "    XX, yy = x_pool[query_index].reshape(1, -1), y_pool[query_index].reshape(1, )\n",
    "    x_train = np.append(x_train, XX, axis = 0)\n",
    "    y_train = np.append(y_train, yy, axis = 0)\n",
    "\n",
    "    # Remove the queried instance from the unlabeled pool.\n",
    "    x_pool, y_pool = np.delete(x_pool, query_index, axis=0), np.delete(y_pool, query_index)\n",
    "    \n",
    "    # Re- training in new data\n",
    "    linear_model.fit(x_train, y_train)\n",
    "    \n",
    "    #Predict given the new point\n",
    "    y_pred = linear_model.predict(x_test)\n",
    "    \n",
    "    #Store performance\n",
    "    model_accuracy = mean_squared_error(y_pred , y_test)\n",
    "    performance_history.append(model_accuracy)\n",
    "\n",
    "\n",
    "    if index % 100 == 0:\n",
    "        print('Accuracy after query {n}: {acc:0.4f}'.format(n=index + 1, acc=model_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2170"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
